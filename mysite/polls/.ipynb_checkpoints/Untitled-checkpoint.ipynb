{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from django.shortcuts import render\n",
    "\n",
    "# Create your views here.\n",
    "from django.http import HttpResponse\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "from scipy import stats\n",
    "import random\n",
    "from django.template.response import TemplateResponse\n",
    "from django.shortcuts import render\n",
    "from django.template import RequestContext\n",
    "# from glove import Corpus, Glove\n",
    "# from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "#include below 2 lines for runtime error/ backend\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import mpld3\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import cgi\n",
    "import spacy\n",
    "import numpy as np\n",
    "from pymagnitude import *\n",
    "# from .models import gameData\n",
    "from django.utils.safestring import mark_safe\n",
    "from django.template import Library\n",
    "import json\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format('~/Downloads/GoogleNews-vectors-negative300.bin', binary=True, limit = 200000)\n",
    "\n",
    "words2 = np.array(model.index2word[:10000])\n",
    "words2[0]\n",
    "\n",
    "nlp = spacy.load('en', disable = ['textcat','ner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#POLLS/GRAPH\n",
    "\n",
    "vec_path = '~/Downloads/GoogleNews-vectors-negative300.bin'\n",
    "word_vecs = word2vec.KeyedVectors.load_word2vec_format(vec_path, binary=True)\n",
    "\n",
    "\n",
    "fastfood = [\"McDonalds\", \"Burger King\", \"KFC\",\"Subway\",\"Taco Bell\",\"Dairy Queen\",\"Dunkin Donuts\",\"Starbucks\",\"Domino Pizza\",\"Panera Bread\",\"Arby\",\"Chipotle\",\"Pizza Hut\",\"Chick-fil-a\",\"Hardee\",\"Popeyes\",\"Whataburger\",\"Quiznos\",\"Zaxby\",\"Steak-n-Shake\",\"Qdoba\",\"Panda Express\",\"Del Taco\",\"Krispy Kreme\",\"Baskin Robbins\"]\n",
    "\n",
    "def vector_array(brand_vectors):\n",
    "    result = {}\n",
    "    for i in brand_vectors:\n",
    "        if ' ' in i:\n",
    "            try:\n",
    "                new = i.replace(\" \", \"_\")\n",
    "                result[i] = word_vecs[new]\n",
    "            except:\n",
    "                pass\n",
    "        elif '-' in i:\n",
    "            try:\n",
    "                new = i.replace(\"-\", \"_\")\n",
    "                result[i] = (word_vecs[new])\n",
    "            except:\n",
    "                pass\n",
    "        else:\n",
    "            try:\n",
    "                result[i] = word_vecs[i]\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "            #if brand name is something like \"taco bell\" or \"Taco Bell\": try \"Taco_Bell\"\n",
    "            #this applies to two word brands only\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.1062429, -1.0716429], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.5230917, -0.7834221], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([-0.27462724, -1.0148548 ], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.7876928, 0.6683703], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_list(dictionary):\n",
    "    list = []\n",
    "    for word, vector in dictionary.items():\n",
    "        list.append(vector)\n",
    "    return list\n",
    "brands = [\"McDonalds\", \"Burger King\", \"KFC\",\"Subway\",\"Taco Bell\",\"Dairy Queen\",\"Dunkin Donuts\",\"Starbucks\",\"Domino Pizza\",\"Panera Bread\",\"Arby\",\"Chipotle\",\"Pizza Hut\",\"Chick-fil-a\",\"Hardee\",\"Popeyes\",\"Whataburger\",\"Quiznos\",\"Zaxby\",\"Steak-n-Shake\",\"Qdoba\",\"Panda Express\",\"Del Taco\",\"Krispy Kreme\",\"Baskin Robbins\"]\n",
    "\n",
    "\n",
    "brand_dict = vector_array(brands)\n",
    "brand_array = np.array(extract_list(brand_dict))\n",
    "pca = PCA(n_components=2)\n",
    "pca_matrix = pca.fit_transform(brand_array)\n",
    "\n",
    "pca_matrix[0]\n",
    "pca_matrix[1]\n",
    "pca_matrix[2]\n",
    "\n",
    "pca.explained_variance_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7662807, -1.2271655], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.66309315, -0.5030892 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.46281523, -0.22708914], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.7366659, 0.5773795], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = [\"Acura\", \"Audi\", \"Bentley\", \"Bmw\", \"Buick\", \"Cadillac\",\"Chevrolet\", \"Chrysler\", \"Dodge\", \"Ferrari\", \"Fiat\", \"Ford\", \"GMC\", \"Honda\", \"Hyundai\", \"Infiniti\", \"Jaguar\", \"Jeep\", \"KIA\", \"Lamborghini\", \"Lexus\", \"Maserati\", \"Mazda\", \"Mercedes\", \"Nissan\", \"Porsche\", \"Rolls-Royce\", \"Subaru\", \"Tesla\", \"Toyota\", \n",
    "          \"Volkswagen\", \"Volvo\"]\n",
    "\n",
    "cars_dict = vector_array(cars)\n",
    "car_array = np.array(extract_list(cars_dict))\n",
    "car_matrix = pca.fit_transform(car_array)\n",
    "car_matrix[0]\n",
    "car_matrix[1]\n",
    "car_matrix[2]\n",
    "\n",
    "pca1.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5230917, -0.7834221], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7876928 0.6683703]\n",
      "[0.11333366 0.09616549]\n"
     ]
    }
   ],
   "source": [
    "pca_matrix[1]\n",
    "\n",
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# [0.7876928 0.6683703]\n",
    "# [0.11333366 0.09616549]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'company'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2[100]\n",
    "\n",
    "df = pandas.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cool', 0.8290217518806458), ('cooler', 0.8196960687637329)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "</s>\n",
      "</s>\n",
      "</s>\n",
      "END\n",
      "START\n",
      "in\n",
      "in\n",
      "in\n",
      "END\n",
      "START\n",
      "for\n",
      "for\n",
      "for\n",
      "END\n",
      "START\n",
      "that\n",
      "that\n",
      "that\n",
      "END\n",
      "START\n",
      "is\n",
      "is\n",
      "is\n",
      "END\n",
      "START\n",
      "on\n",
      "on\n",
      "on\n",
      "END\n",
      "START\n",
      "##\n",
      "##\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['</s>', 'in', 'for', ..., 'modeling', 'Worldwide', 'shaky'],\n",
       "      dtype='<U36')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result4 = model.most_similar_cosmul(positive=[\"Nike\", \"cool\"], negative=[\"adidas\"],topn=2)\n",
    "result4\n",
    "words2[3] \n",
    "# p = nlp(w)[-1].pos_\n",
    "i = 0 \n",
    "for w in words2:\n",
    "    print(\"START\")\n",
    "    print(w)\n",
    "    w = str(w)\n",
    "    print(w)\n",
    "    if i >5:\n",
    "        break\n",
    "    print(nlp(w))\n",
    "    p = nlp(w)[-1].pos_\n",
    "\n",
    "    print(\"END\")\n",
    "    i +=1 \n",
    "\n",
    "words2\n",
    "len(model.index2word[:10000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['X', 'ADP', 'ADP', ..., 'VERB', 'ADV', 'ADJ'], dtype='<U5')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_pos = []\n",
    "proper = []\n",
    "\n",
    "for w in words2:\n",
    "    w = str(w)\n",
    "    if w != '_':\n",
    "        w = w.replace('_', ' ')\n",
    "    p = nlp(w)[-1].pos_\n",
    "    words_pos.append(p)\n",
    "    proper.append(w != w.lower())\n",
    "words_pos = np.array(words_pos)\n",
    "proper = np.array(proper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "words_pos[0]\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Christine/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.1291504e-03, -8.9645386e-04,  3.1852722e-04, ...,\n",
       "        -1.5640259e-03, -1.2302399e-04, -8.6307526e-05],\n",
       "       [ 7.0312500e-02,  8.6914062e-02,  8.7890625e-02, ...,\n",
       "        -4.7607422e-02,  1.4465332e-02, -6.2500000e-02],\n",
       "       [-1.1779785e-02, -4.7363281e-02,  4.4677734e-02, ...,\n",
       "         7.1289062e-02, -3.4912109e-02,  2.4169922e-02],\n",
       "       ...,\n",
       "       [-5.2734375e-02, -7.6171875e-02, -1.2988281e-01, ...,\n",
       "        -1.4453125e-01, -8.4472656e-02, -2.5585938e-01],\n",
       "       [ 2.4707031e-01, -2.5781250e-01,  8.6425781e-02, ...,\n",
       "         5.1513672e-02,  7.5195312e-02, -3.6132812e-02],\n",
       "       [ 1.8066406e-01,  1.0058594e-01, -8.6914062e-02, ...,\n",
       "        -2.0898438e-01,  1.0253906e-01,  8.3496094e-02]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = model.syn0[:10000]\n",
    "arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'wr'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['hello', 'hello', 'no', 'what']\n",
    "\n",
    "test.count(\"hello\")\n",
    "a= set(test)\n",
    "type(a)\n",
    "max(test, key = len)\n",
    "\n",
    "'draw'[::-2]\n",
    "\n",
    "for w in a:\n",
    "    break \n",
    "    \n",
    "    \n",
    "final_output_list = []\n",
    "\n",
    "for i in range(0, len(final_output_list)):\n",
    "    component_i = model.get_vector(phrase)\n",
    "    result_i = get_similar(component, pos='ADJ', exclude_proper=True, top=number2)\n",
    "    final_output_list.append(result_i)\n",
    "\n",
    "    \n",
    "component = model.get_vector(phrase)\n",
    "resultPhrase2 = get_similar(component, pos='ADJ', exclude_proper=True, top=number2)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
